<!doctype html>
<html lang='en'>
<head>
    <meta charset='utf-8'>
    <title>state of ai - oct 2025</title>
    <link rel='icon' type='image/x-icon' href='../img/favicon.ico'>
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="../css/blog.css">
</head>

<body>
    <div id="header"><h2><a href="../index.html">main</a> / <a href="../blog.html">blog</a> / state of ai - oct 2025</h2></div>
    <span id="published">oct 29 25</span><br>
    <i id="edited"><!-- !EDITED_READABLE --></i>

    <div class="post-body">
<h2>What's happened in AI?</h2>
<p>As I pointed out some months ago from the insight I gleaned from the apparently exceedingly abstruse method of... reading OpenAI's own official statements, GPT-5 proved to not be an exponential leap in quality along the lines of previous leaps in iteration. </p>
<p>A growing subset of the tech-y zeitgeist has since acknowledged this slowdown in the wake of GPT-5's release and OpenAI deciding their true calling was building ai tiktok and ad features for ChatGPT.</p>
<p>The main improvement in the news is AI video from what I have seen, which I write about more in the next section.</p>
<p>The pro- vs. anti- ai debates are raging ever fiercer online, and interestingly it's become more and more mainstream. Though it's far from reaching true mainstream saturation the sentiment online is far stronger for anti-ai. I expected more apathy from the broader uninvested population in honesty. My working theory is that generative AI has become something of a proxy for pro/anti corporate arguments, creating a broader sense of investment that builds off existing sentiment.</p>
<p>I believe Google is expected to release Gemini 3 sometime before the end of 2025 though I'm not exactly holding my breath in anticipation. </p>
<h2>The New Golden Child - AI Video</h2>
<p>Ai video saw the sort of rapid growth that other media had in the past this year, and I've seen plenty of posts talking and demoing it within certain spaces. Its consistency and reduction of the number of "AI-y" artifacts have improved quite a bit. This presumably will follow the same trajectory as the other mediums though--at its best, a technically competent but quite creatively lacking result. And given the complete lack of proper integration into real art tools it won't be possible to fix the problems. I really wonder why adobe hasn't put out something decent for this yet. It's certainly not because of any moral qualms at the least.</p>
<h2>The Future of AI Art</h2>
<p>As I see it there are basically 3 ways that this could go down in the near future: 
1.  Gen AI escapes its current magnitude of capability and creates art better than pretty much any human is capable of
2. Gen AI stays within its current magnitude but becomes a constant in the art pipeline
3. Gen AI is unable to be integrated into pipelines effectively and is marginalized to a mild curiousity</p>
<p>Given that it seems pretty clear that the development of "understanding" as a whole for AI is on pause, the likelihood of 1) doesn't seem to be very high. Similarly for 3) I don't see why existing AI tools with some polishing and feature extension wouldn't already be there in terms of capability. I suppose that already shows that I imagine 2) is the most likely outcome. It's interesting how it seems like it will "work out" that way.. like a picturesque ending to a story where technology empowers people instead of replacing them. Maybe there is a cosmic scriptwriter after all...</p>
<h2>Most Legitimate AI (LLM) usecases</h2>
<p>LLMs are far from useless--they just also don't magically solve everything. Things usually tend to end up like that, I suppose because we can't help but get excited and a little ahead of ourselves with predictions. </p>
<p>Anyhow, the most promising applications for LLMs seem to be: </p>
<ul>
<li>
<p>actually good voice assistants</p>
<ul>
<li>This seems like by far the most obvious application to me as well as being actually useful for people but it's clearly not much of a priority. There is the significant hurdle of it being in every private company's interest to keep you locked into their app instead of providing an API to accomplish tasks outside of it via agents/assistants. Apple definitely has the clout to strongarm companies into doing so if it really cared to, but I guess they're more interested in... what? What is Apple even doing these days? Changing all their app modals to transparent panels? </li>
</ul>
</li>
<li>
<p>finding "needles in a haystack" </p>
<ul>
<li>I saw news that a research model was able to bring certain papers to a mathematician's attention which enabled some discoveries. I believe similar events have occurred in biotech.</li>
</ul>
</li>
<li>
<p>naturalistic search queries</p>
<ul>
<li>Half if not more of finding a solution online is trying to figure out the proper terms for what you're trying to do so the search engine can bring up the relevant resources. LLMs can act as a mediating layer here.</li>
</ul>
</li>
<li>
<p>blackboxing programming boilerplate</p>
<ul>
<li>Very well known already. Though LLMs aren't to be trusted with an entire codebase they are plenty sufficient for blackboxing out certain functionality.</li>
</ul>
</li>
</ul>
<h2>ASI Arms Race?</h2>
<p>Just recently an "open letter" calling for a pause on ASI development until 700 celebrity names calling for a pause on ASI development until human alignment could be better verified was released. It included names like Geoffrey Hinton and other AI researchers, Steve Wozniak and a smattering of other figures like the Duke and Duchess of Sussex (I mean sure why not).</p>
<p>Given the vast economic/political (really the same, I suppose) leverage that control over an ASI would grant a country over the rest of the world, I doubt any of the major players (which I think are basically just the US and China) are feeling particularly incentivised to step down and potentially give their competitor the freedom to build a lead. Perhaps in a world where there was less meaningful material gain to be made for playing with such unknowns it would be possible to have more of a discussion but I can hardly imagine this playing out so cooperatively. </p>
<p>However, in light of recent developments there is limited reason to believe that it will be a problem we will have to deal with in the near future. LLMs are likely not the path to ASI, and barring that it's not like there's some other immediately promising technology just waiting to be reaped. In a sense, we're back to where we started. Well, not entirely since LLMs do have the power to perform that sort of "needle searching" that isn't feasible for humans. Maybe this will be a not insignificant accelerator, though I would hazard a guess that it will more likely just be a flat saving of time rather than something that scales particularly.</p>
    </div>

</body>
</html>
